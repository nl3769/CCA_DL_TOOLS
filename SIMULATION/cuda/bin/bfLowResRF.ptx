//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31833905
// Cuda compilation tools, release 11.8, V11.8.89
// Based on NVVM 7.0.1
//

.version 7.8
.target sm_75
.address_size 64

	// .globl	das_low_res

.visible .entry das_low_res(
	.param .u64 das_low_res_param_0,
	.param .u64 das_low_res_param_1,
	.param .u64 das_low_res_param_2,
	.param .u64 das_low_res_param_3,
	.param .u32 das_low_res_param_4,
	.param .u32 das_low_res_param_5,
	.param .u32 das_low_res_param_6,
	.param .u32 das_low_res_param_7,
	.param .f64 das_low_res_param_8,
	.param .f64 das_low_res_param_9,
	.param .u64 das_low_res_param_10,
	.param .u32 das_low_res_param_11,
	.param .u64 das_low_res_param_12,
	.param .u64 das_low_res_param_13,
	.param .f64 das_low_res_param_14
)
{
	.reg .pred 	%p<17>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<99>;
	.reg .b64 	%rd<47>;


	ld.param.u64 	%rd13, [das_low_res_param_0];
	ld.param.u64 	%rd16, [das_low_res_param_1];
	ld.param.u64 	%rd17, [das_low_res_param_2];
	ld.param.u64 	%rd18, [das_low_res_param_3];
	ld.param.u32 	%r23, [das_low_res_param_4];
	ld.param.u32 	%r24, [das_low_res_param_5];
	ld.param.u32 	%r25, [das_low_res_param_6];
	ld.param.u32 	%r26, [das_low_res_param_7];
	ld.param.f64 	%fd12, [das_low_res_param_8];
	ld.param.f64 	%fd13, [das_low_res_param_9];
	ld.param.u64 	%rd19, [das_low_res_param_10];
	ld.param.u32 	%r27, [das_low_res_param_11];
	ld.param.u64 	%rd14, [das_low_res_param_12];
	ld.param.u64 	%rd15, [das_low_res_param_13];
	ld.param.f64 	%fd14, [das_low_res_param_14];
	cvta.to.global.u64 	%rd1, %rd19;
	cvta.to.global.u64 	%rd2, %rd16;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd17;
	mov.u32 	%r28, %ntid.x;
	mov.u32 	%r29, %ctaid.x;
	mul.lo.s32 	%r1, %r29, %r28;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r3, %r1, %r2;
	mov.u32 	%r30, %ntid.y;
	mov.u32 	%r31, %ctaid.y;
	mov.u32 	%r32, %tid.y;
	mad.lo.s32 	%r4, %r31, %r30, %r32;
	setp.ge.s32 	%p1, %r3, %r25;
	setp.ge.s32 	%p2, %r4, %r26;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_12;

	cvta.to.global.u64 	%rd20, %rd14;
	mad.lo.s32 	%r5, %r3, %r26, %r4;
	mul.lo.s32 	%r6, %r26, %r25;
	mul.wide.s32 	%rd21, %r27, 8;
	add.s64 	%rd22, %rd4, %rd21;
	mul.wide.s32 	%rd23, %r3, 8;
	add.s64 	%rd5, %rd20, %rd23;
	ld.global.f64 	%fd15, [%rd5];
	ld.global.f64 	%fd16, [%rd22];
	sub.f64 	%fd17, %fd16, %fd15;
	add.s64 	%rd24, %rd3, %rd21;
	cvta.to.global.u64 	%rd25, %rd15;
	mul.wide.s32 	%rd26, %r4, 8;
	add.s64 	%rd6, %rd25, %rd26;
	ld.global.f64 	%fd18, [%rd6];
	ld.global.f64 	%fd19, [%rd24];
	sub.f64 	%fd20, %fd19, %fd18;
	mul.f64 	%fd21, %fd20, %fd20;
	fma.rn.f64 	%fd22, %fd17, %fd17, %fd21;
	sqrt.rn.f64 	%fd1, %fd22;
	setp.lt.s32 	%p4, %r23, 1;
	@%p4 bra 	$L__BB0_12;

	add.s32 	%r34, %r24, -1;
	cvt.rn.f64.s32 	%fd2, %r34;
	mad.lo.s32 	%r35, %r6, %r27, %r5;
	mul.wide.s32 	%rd27, %r35, 8;
	add.s64 	%rd7, %rd1, %rd27;
	cvta.to.global.u64 	%rd28, %rd13;
	mul.wide.s32 	%rd29, %r5, 8;
	add.s64 	%rd8, %rd28, %rd29;
	and.b32  	%r7, %r23, 1;
	setp.eq.s32 	%p5, %r23, 1;
	mov.u32 	%r56, 0;
	@%p5 bra 	$L__BB0_9;

	sub.s32 	%r55, %r23, %r7;
	shl.b32 	%r9, %r24, 1;
	add.s32 	%r38, %r2, %r25;
	add.s32 	%r39, %r38, %r1;
	mad.lo.s32 	%r52, %r26, %r39, %r4;
	shl.b32 	%r11, %r6, 1;
	mov.u32 	%r51, %r5;
	mov.u64 	%rd45, %rd4;
	mov.u64 	%rd46, %rd3;
	mov.u32 	%r53, %r56;

$L__BB0_4:
	ld.global.f64 	%fd98, [%rd5];
	ld.global.f64 	%fd23, [%rd45];
	sub.f64 	%fd24, %fd23, %fd98;
	ld.global.f64 	%fd97, [%rd6];
	ld.global.f64 	%fd25, [%rd46];
	sub.f64 	%fd26, %fd25, %fd97;
	mul.f64 	%fd27, %fd26, %fd26;
	fma.rn.f64 	%fd28, %fd24, %fd24, %fd27;
	sqrt.rn.f64 	%fd29, %fd28;
	add.f64 	%fd30, %fd1, %fd29;
	div.rn.f64 	%fd31, %fd30, %fd12;
	add.f64 	%fd32, %fd31, %fd14;
	fma.rn.f64 	%fd5, %fd32, %fd13, 0d3FF0000000000000;
	setp.ltu.f64 	%p6, %fd5, 0d3FF0000000000000;
	setp.gtu.f64 	%p7, %fd5, %fd2;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB0_6;

	cvt.rmi.f64.f64 	%fd33, %fd5;
	cvt.rzi.s32.f64 	%r40, %fd33;
	add.s32 	%r41, %r40, %r53;
	mul.wide.s32 	%rd30, %r41, 8;
	add.s64 	%rd31, %rd2, %rd30;
	add.s32 	%r42, %r40, 1;
	cvt.rn.f64.s32 	%fd34, %r42;
	sub.f64 	%fd35, %fd34, %fd5;
	ld.global.f64 	%fd36, [%rd31];
	mul.f64 	%fd37, %fd36, %fd35;
	cvt.rn.f64.s32 	%fd38, %r40;
	sub.f64 	%fd39, %fd5, %fd38;
	ld.global.f64 	%fd40, [%rd31+8];
	fma.rn.f64 	%fd41, %fd40, %fd39, %fd37;
	mul.wide.s32 	%rd32, %r51, 8;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f64 	%fd42, [%rd33];
	ld.global.f64 	%fd43, [%rd7];
	mul.f64 	%fd44, %fd43, %fd42;
	ld.global.f64 	%fd45, [%rd8];
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	st.global.f64 	[%rd8], %fd46;
	ld.global.f64 	%fd98, [%rd5];
	ld.global.f64 	%fd97, [%rd6];

$L__BB0_6:
	ld.global.f64 	%fd47, [%rd45+8];
	sub.f64 	%fd48, %fd47, %fd98;
	ld.global.f64 	%fd49, [%rd46+8];
	sub.f64 	%fd50, %fd49, %fd97;
	mul.f64 	%fd51, %fd50, %fd50;
	fma.rn.f64 	%fd52, %fd48, %fd48, %fd51;
	sqrt.rn.f64 	%fd53, %fd52;
	add.f64 	%fd54, %fd1, %fd53;
	div.rn.f64 	%fd55, %fd54, %fd12;
	add.f64 	%fd56, %fd55, %fd14;
	fma.rn.f64 	%fd10, %fd56, %fd13, 0d3FF0000000000000;
	setp.ltu.f64 	%p9, %fd10, 0d3FF0000000000000;
	setp.gtu.f64 	%p10, %fd10, %fd2;
	or.pred  	%p11, %p9, %p10;
	@%p11 bra 	$L__BB0_8;

	cvt.rmi.f64.f64 	%fd57, %fd10;
	cvt.rzi.s32.f64 	%r43, %fd57;
	add.s32 	%r44, %r24, %r43;
	add.s32 	%r45, %r44, %r53;
	mul.wide.s32 	%rd34, %r45, 8;
	add.s64 	%rd35, %rd2, %rd34;
	add.s32 	%r46, %r43, 1;
	cvt.rn.f64.s32 	%fd58, %r46;
	sub.f64 	%fd59, %fd58, %fd10;
	ld.global.f64 	%fd60, [%rd35];
	mul.f64 	%fd61, %fd60, %fd59;
	cvt.rn.f64.s32 	%fd62, %r43;
	sub.f64 	%fd63, %fd10, %fd62;
	ld.global.f64 	%fd64, [%rd35+8];
	fma.rn.f64 	%fd65, %fd64, %fd63, %fd61;
	mul.wide.s32 	%rd36, %r52, 8;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.f64 	%fd66, [%rd37];
	ld.global.f64 	%fd67, [%rd7];
	mul.f64 	%fd68, %fd67, %fd66;
	ld.global.f64 	%fd69, [%rd8];
	fma.rn.f64 	%fd70, %fd68, %fd65, %fd69;
	st.global.f64 	[%rd8], %fd70;

$L__BB0_8:
	add.s32 	%r56, %r56, 2;
	add.s32 	%r53, %r53, %r9;
	add.s32 	%r52, %r52, %r11;
	add.s64 	%rd46, %rd46, 16;
	add.s64 	%rd45, %rd45, 16;
	add.s32 	%r51, %r51, %r11;
	add.s32 	%r55, %r55, -2;
	setp.ne.s32 	%p12, %r55, 0;
	@%p12 bra 	$L__BB0_4;

$L__BB0_9:
	setp.eq.s32 	%p13, %r7, 0;
	@%p13 bra 	$L__BB0_12;

	mul.wide.s32 	%rd38, %r56, 8;
	add.s64 	%rd39, %rd4, %rd38;
	ld.global.f64 	%fd71, [%rd5];
	ld.global.f64 	%fd72, [%rd39];
	sub.f64 	%fd73, %fd72, %fd71;
	add.s64 	%rd40, %rd3, %rd38;
	ld.global.f64 	%fd74, [%rd6];
	ld.global.f64 	%fd75, [%rd40];
	sub.f64 	%fd76, %fd75, %fd74;
	mul.f64 	%fd77, %fd76, %fd76;
	fma.rn.f64 	%fd78, %fd73, %fd73, %fd77;
	sqrt.rn.f64 	%fd79, %fd78;
	add.f64 	%fd80, %fd1, %fd79;
	div.rn.f64 	%fd81, %fd80, %fd12;
	add.f64 	%fd82, %fd81, %fd14;
	fma.rn.f64 	%fd11, %fd82, %fd13, 0d3FF0000000000000;
	setp.ltu.f64 	%p14, %fd11, 0d3FF0000000000000;
	setp.gtu.f64 	%p15, %fd11, %fd2;
	or.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB0_12;

	cvt.rmi.f64.f64 	%fd83, %fd11;
	cvt.rzi.s32.f64 	%r47, %fd83;
	mad.lo.s32 	%r48, %r56, %r6, %r5;
	mad.lo.s32 	%r49, %r56, %r24, %r47;
	mul.wide.s32 	%rd41, %r49, 8;
	add.s64 	%rd42, %rd2, %rd41;
	add.s32 	%r50, %r47, 1;
	cvt.rn.f64.s32 	%fd84, %r50;
	sub.f64 	%fd85, %fd84, %fd11;
	ld.global.f64 	%fd86, [%rd42];
	mul.f64 	%fd87, %fd86, %fd85;
	cvt.rn.f64.s32 	%fd88, %r47;
	sub.f64 	%fd89, %fd11, %fd88;
	ld.global.f64 	%fd90, [%rd42+8];
	fma.rn.f64 	%fd91, %fd90, %fd89, %fd87;
	mul.wide.s32 	%rd43, %r48, 8;
	add.s64 	%rd44, %rd1, %rd43;
	ld.global.f64 	%fd92, [%rd44];
	ld.global.f64 	%fd93, [%rd7];
	mul.f64 	%fd94, %fd93, %fd92;
	ld.global.f64 	%fd95, [%rd8];
	fma.rn.f64 	%fd96, %fd94, %fd91, %fd95;
	st.global.f64 	[%rd8], %fd96;

$L__BB0_12:
	ret;

}

